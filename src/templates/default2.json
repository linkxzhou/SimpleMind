{"data":{"text":"深度学习知识总结","expand":true,"uid":"09675dac-23cf-42a6-8518-6b5e4004aa54","isActive":false},"children":[{"data":{"text":"神经网络基础理论与架构","note":"神经网络是深度学习的核心基础，包括感知机、多层感知机、激活函数等基本概念。理解神经元的工作原理、网络层次结构、前向传播和反向传播机制是掌握深度学习的前提。从生物神经元到人工神经元的抽象过程，以及如何通过多层非线性变换来逼近复杂函数，这些都是构建现代深度学习模型的理论基石。","nextSystemPrompt":"基于神经网络基础理论，总结出感知机模型、激活函数、网络结构设计等核心子知识点","color":"#4A90E2","expand":true,"richText":false,"isActive":false,"uid":"e3dac7b2-9a1b-4895-8c30-690975c4ebf2"},"children":[{"data":{"text":"感知机与多层感知机","note":"感知机是最简单的神经网络模型，只能解决线性可分问题。多层感知机通过增加隐藏层解决了非线性问题，是现代深度网络的雏形。","nextSystemPrompt":"","color":"#7ED321","expand":true,"richText":false,"isActive":false,"uid":"4d40f694-1eab-4aa3-b1f6-b36923734f24"},"children":[]},{"data":{"text":"激活函数设计与选择","note":"激活函数为神经网络引入非线性特性，包括Sigmoid、ReLU、Tanh等。不同激活函数有不同的梯度特性和计算效率。","nextSystemPrompt":"","color":"#F5A623","expand":true,"richText":false,"isActive":false,"uid":"df9841fd-4a2c-4d99-8e2b-93fdcc9c1908"},"children":[]},{"data":{"text":"前向传播机制","note":"数据从输入层逐层向前传递，每层进行线性变换和非线性激活，最终得到网络输出的完整过程。","nextSystemPrompt":"","color":"#BD10E0","expand":true,"richText":false,"isActive":false,"uid":"2e941bfd-e876-40fa-b21b-ffc6b6a3de02"},"children":[]},{"data":{"text":"反向传播算法","note":"通过链式法则计算损失函数对各层参数的梯度，实现参数更新的核心算法，是深度学习训练的基础。","nextSystemPrompt":"","color":"#D0021B","expand":true,"richText":false,"isActive":false,"uid":"a0f4308b-0897-4fb5-aa45-2a3932555f80"},"children":[]},{"data":{"text":"权重初始化策略","note":"合理的权重初始化能够避免梯度消失或爆炸问题，包括Xavier初始化、He初始化等方法。","nextSystemPrompt":"","color":"#50E3C2","expand":true,"richText":false,"isActive":false,"uid":"b19d664c-497c-42df-9f7f-14aeeb2e35de"},"children":[]},{"data":{"text":"损失函数设计","note":"衡量模型预测与真实值差异的函数，包括均方误差、交叉熵等，指导模型训练方向。","nextSystemPrompt":"","color":"#9013FE","expand":true,"richText":false,"isActive":false,"uid":"29ee298e-441e-4b28-97d2-83e11356c602"},"children":[]},{"data":{"text":"梯度下降优化","note":"通过梯度信息更新模型参数的优化方法，包括SGD、Adam、RMSprop等不同优化器。","nextSystemPrompt":"","color":"#FF6900","expand":true,"richText":false,"isActive":false,"uid":"03fb365f-9e14-47b5-94b9-11f540ba4c6e"},"children":[]},{"data":{"text":"网络深度与宽度","note":"网络层数和每层神经元数量的设计原则，影响模型的表达能力和训练难度。","nextSystemPrompt":"","color":"#FCB900","expand":true,"richText":false,"isActive":false,"uid":"e3510509-6223-4c99-bc01-e8617ce7c399"},"children":[]},{"data":{"text":"万能逼近定理","note":"理论证明多层神经网络能够逼近任意连续函数，为深度学习的理论基础提供支撑。","nextSystemPrompt":"","color":"#00D084","expand":true,"richText":false,"isActive":false,"uid":"5f578b93-83e8-4715-9856-9a1ecc4707d4"},"children":[]},{"data":{"text":"计算图与自动微分","note":"将神经网络表示为计算图，通过自动微分技术高效计算梯度，是现代深度学习框架的核心。","nextSystemPrompt":"","color":"#8B572A","expand":true,"richText":false,"isActive":false,"uid":"c365b395-0174-4fcc-9ca8-033ed432aaa0"},"children":[]}]},{"data":{"text":"卷积神经网络CNN架构","note":"卷积神经网络专门用于处理具有网格结构的数据，如图像。通过卷积层、池化层、全连接层的组合，能够自动学习图像的层次化特征表示。CNN利用局部连接、权重共享、平移不变性等特性，大大减少了参数数量，提高了训练效率。从LeNet到ResNet的发展历程展现了CNN架构设计的演进。","nextSystemPrompt":"基于卷积神经网络架构，总结出卷积层、池化层、经典CNN模型等关键子知识点","color":"#E74C3C","expand":true,"richText":false,"isActive":false,"uid":"22b8027e-9d2b-4078-b169-12b5f80d193c"},"children":[{"data":{"text":"卷积层原理与设计","note":"通过卷积核在输入特征图上滑动，提取局部特征。包括卷积核大小、步长、填充等超参数的设计原则。","nextSystemPrompt":"","color":"#3498DB","expand":true,"richText":false,"isActive":false,"uid":"f3e43e6e-a67e-4239-8ad6-003c9b0db1e9"},"children":[]},{"data":{"text":"池化层降维机制","note":"通过最大池化或平均池化减少特征图尺寸，降低计算复杂度，增强模型的平移不变性。","nextSystemPrompt":"","color":"#2ECC71","expand":true,"richText":false,"isActive":false,"uid":"a719886a-c45c-4d13-91ab-bad51af0b5fa"},"children":[]},{"data":{"text":"LeNet经典架构","note":"最早的卷积神经网络之一，用于手写数字识别，奠定了CNN的基本架构模式。","nextSystemPrompt":"","color":"#F39C12","expand":true,"richText":false,"isActive":false,"uid":"84d819e0-5d9b-4e46-a9ea-d29723a0961d"},"children":[]},{"data":{"text":"AlexNet深度突破","note":"首次在ImageNet上取得突破性成果的深度CNN，引入了ReLU激活函数和Dropout技术。","nextSystemPrompt":"","color":"#9B59B6","expand":true,"richText":false,"isActive":false,"uid":"edeed448-5b33-4206-8e8d-35c1060db2c9"},"children":[]},{"data":{"text":"VGG网络设计哲学","note":"通过使用小卷积核和增加网络深度来提升性能，展现了网络深度的重要性。","nextSystemPrompt":"","color":"#1ABC9C","expand":true,"richText":false,"isActive":false,"uid":"27d64feb-81ba-456d-9e59-2adde27bea9f"},"children":[]},{"data":{"text":"ResNet残差连接","note":"通过残差连接解决深度网络的梯度消失问题，使得训练超深网络成为可能。","nextSystemPrompt":"","color":"#E67E22","expand":true,"richText":false,"isActive":false,"uid":"7c40d365-17b6-430d-8ea2-afc032d999eb"},"children":[]},{"data":{"text":"Inception模块设计","note":"在同一层中使用多种尺寸的卷积核，增加网络的宽度和特征提取能力。","nextSystemPrompt":"","color":"#34495E","expand":true,"richText":false,"isActive":false,"uid":"5b361c0c-66a3-4d2d-9a47-347cbd15103d"},"children":[]},{"data":{"text":"批量归一化技术","note":"通过归一化每一批数据的分布，加速训练收敛，减少对初始化的依赖。","nextSystemPrompt":"","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"d5e9a284-72c1-4e53-8b3a-e9570c2f136d"},"children":[]},{"data":{"text":"特征图可视化分析","note":"通过可视化CNN各层学到的特征图，理解网络的学习过程和特征提取机制。","nextSystemPrompt":"","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"36ed0e85-525a-42c1-bce2-fc68fbad604b"},"children":[]},{"data":{"text":"卷积变种与改进","note":"包括深度可分离卷积、空洞卷积、转置卷积等卷积操作的变种和改进方法。","nextSystemPrompt":"","color":"#8E44AD","expand":true,"richText":false,"isActive":false,"uid":"ecd2efe6-9fa1-4a7f-ae46-afb923b129de"},"children":[]}]},{"data":{"text":"循环神经网络RNN序列建模","note":"循环神经网络专门处理序列数据，通过隐藏状态在时间步之间传递信息，能够建模变长序列的时序依赖关系。RNN在自然语言处理、语音识别、时间序列预测等领域有广泛应用。从基础RNN到LSTM、GRU的发展，解决了长期依赖问题，使得处理更长序列成为可能。","nextSystemPrompt":"基于循环神经网络序列建模，总结出基础RNN、LSTM、GRU、序列到序列等核心子知识点","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"2f9902b0-41b8-4fc3-adcf-6ab1fa3bafe1"},"children":[{"data":{"text":"基础RNN架构原理","note":"通过循环连接在时间步之间共享参数，隐藏状态承载历史信息，实现序列建模的基本机制。","nextSystemPrompt":"","color":"#3498DB","expand":true,"richText":false,"isActive":false,"uid":"dc5f2763-bd79-4127-ba12-1b5cdfb41ea1"},"children":[]},{"data":{"text":"LSTM长短期记忆","note":"通过门控机制控制信息流动，包括遗忘门、输入门、输出门，有效解决梯度消失和长期依赖问题。","nextSystemPrompt":"","color":"#E74C3C","expand":true,"richText":false,"isActive":false,"uid":"d686d480-ef91-4da3-97de-5620e4aa213c"},"children":[]},{"data":{"text":"GRU门控循环单元","note":"简化版的LSTM，只有重置门和更新门，参数更少但性能相近，计算效率更高。","nextSystemPrompt":"","color":"#F39C12","expand":true,"richText":false,"isActive":false,"uid":"ca3f3fe7-3f46-45e4-b460-9ac0e5f55809"},"children":[]},{"data":{"text":"双向RNN结构","note":"同时从前向和后向处理序列，能够利用完整的上下文信息，提升序列建模性能。","nextSystemPrompt":"","color":"#9B59B6","expand":true,"richText":false,"isActive":false,"uid":"3c732589-b074-4f30-99d4-5ea2548b3dd7"},"children":[]},{"data":{"text":"序列到序列模型","note":"编码器-解码器架构，将输入序列编码为固定表示，再解码为输出序列，广泛用于机器翻译。","nextSystemPrompt":"","color":"#1ABC9C","expand":true,"richText":false,"isActive":false,"uid":"e06cfd05-8eb0-40c7-a7c3-4b894a28bddd"},"children":[]},{"data":{"text":"注意力机制引入","note":"允许模型在生成每个输出时关注输入序列的不同部分，解决了固定长度编码的信息瓶颈问题。","nextSystemPrompt":"","color":"#E67E22","expand":true,"richText":false,"isActive":false,"uid":"1fe6886f-8c8c-4739-9f9b-dcacf2032fc7"},"children":[]},{"data":{"text":"梯度消失与爆炸","note":"RNN训练中的核心问题，梯度在时间步传播时会指数级衰减或增长，影响长序列学习能力。","nextSystemPrompt":"","color":"#34495E","expand":true,"richText":false,"isActive":false,"uid":"d0098775-3d2e-4a7d-a7c6-0dafd946a94f"},"children":[]},{"data":{"text":"时间反向传播算法","note":"RNN的训练算法，通过时间展开网络，应用标准反向传播计算梯度并更新参数。","nextSystemPrompt":"","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"4b4a7207-b472-46c6-b304-f5745fb4f163"},"children":[]},{"data":{"text":"序列生成与采样","note":"使用训练好的RNN生成新序列的方法，包括贪心搜索、束搜索、随机采样等策略。","nextSystemPrompt":"","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"8e394e01-7565-48ef-9462-01d9f1126fda"},"children":[]},{"data":{"text":"RNN应用场景分析","note":"语言建模、情感分析、命名实体识别、语音识别等自然语言处理和时序数据分析任务。","nextSystemPrompt":"","color":"#8E44AD","expand":true,"richText":false,"isActive":false,"uid":"88ca898a-b444-4d66-8540-277a012dc5cd"},"children":[]}]},{"data":{"text":"Transformer注意力架构","note":"Transformer完全基于注意力机制，摒弃了循环和卷积结构，通过自注意力机制并行处理序列中的所有位置。多头注意力、位置编码、残差连接等设计使其在自然语言处理任务上取得突破性进展。Transformer架构催生了BERT、GPT等预训练模型，开启了大模型时代。","nextSystemPrompt":"基于Transformer注意力架构，总结出自注意力机制、多头注意力、位置编码、预训练模型等子知识点","color":"#9B59B6","expand":true,"richText":false,"isActive":false,"uid":"c72a2d61-8127-4058-a505-c0b4e4c8f844"},"children":[{"data":{"text":"自注意力机制原理","note":"通过查询、键、值三个矩阵计算序列内部元素之间的关联度，实现全局信息交互。","nextSystemPrompt":"","color":"#3498DB","expand":true,"richText":false,"isActive":false,"uid":"e0780618-9da4-4c1e-a11f-f9fd2b85023b"},"children":[]},{"data":{"text":"多头注意力设计","note":"并行运行多个注意力头，每个头关注不同的表示子空间，增强模型的表达能力。","nextSystemPrompt":"","color":"#E74C3C","expand":true,"richText":false,"isActive":false,"uid":"b0b37727-cbe2-4c7c-80d4-c0e6f13fb27e"},"children":[]},{"data":{"text":"位置编码机制","note":"由于Transformer没有循环结构，需要通过位置编码为模型提供序列位置信息。","nextSystemPrompt":"","color":"#F39C12","expand":true,"richText":false,"isActive":false,"uid":"8d59f464-4d7e-458c-8037-4d470a50c88e"},"children":[]},{"data":{"text":"编码器解码器结构","note":"编码器处理输入序列，解码器生成输出序列，通过交叉注意力连接两个部分。","nextSystemPrompt":"","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"b80e3d98-e3d3-436c-84f0-87f4f2fb9774"},"children":[]},{"data":{"text":"层归一化与残差","note":"在每个子层后应用层归一化和残差连接，稳定训练过程，支持更深的网络结构。","nextSystemPrompt":"","color":"#1ABC9C","expand":true,"richText":false,"isActive":false,"uid":"49cbe47b-2e78-4fc0-8e7e-9bd0f2d496af"},"children":[]},{"data":{"text":"BERT预训练模型","note":"双向编码器表示，通过掩码语言模型和下一句预测任务进行预训练，在多项NLP任务上刷新记录。","nextSystemPrompt":"","color":"#E67E22","expand":true,"richText":false,"isActive":false,"uid":"453aab8a-f593-43f7-ba8e-029e94b5ea29"},"children":[]},{"data":{"text":"GPT生成式预训练","note":"基于Transformer解码器的自回归语言模型，通过大规模文本预训练获得强大的文本生成能力。","nextSystemPrompt":"","color":"#34495E","expand":true,"richText":false,"isActive":false,"uid":"a461169b-6a74-49d9-b0a1-7995d8c6de4e"},"children":[]},{"data":{"text":"缩放点积注意力","note":"Transformer中使用的注意力计算方法，通过缩放因子避免softmax函数进入饱和区域。","nextSystemPrompt":"","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"a24bd388-f0bd-453f-99fd-36d0c3433e61"},"children":[]},{"data":{"text":"掩码机制设计","note":"在训练和推理中控制注意力的计算范围，包括填充掩码和因果掩码等不同类型。","nextSystemPrompt":"","color":"#8E44AD","expand":true,"richText":false,"isActive":false,"uid":"0b814e85-4a42-4bbd-b489-0b445d0127e4"},"children":[]},{"data":{"text":"Transformer变种改进","note":"包括Reformer、Linformer、Performer等针对计算复杂度和内存效率的改进版本。","nextSystemPrompt":"","color":"#D35400","expand":true,"richText":false,"isActive":false,"uid":"6a98e8da-c96c-4139-a940-c122c37c5516"},"children":[]}]},{"data":{"text":"生成对抗网络GAN","note":"生成对抗网络由生成器和判别器组成，通过对抗训练学习数据分布。生成器试图生成逼真的假数据，判别器试图区分真假数据，两者在博弈中共同提升。GAN在图像生成、数据增强、风格迁移等领域展现出强大能力，但训练不稳定和模式崩塌等问题也是研究重点。","nextSystemPrompt":"基于生成对抗网络，总结出生成器设计、判别器架构、对抗训练、GAN变种等核心子知识点","color":"#E67E22","expand":true,"richText":false,"isActive":false,"uid":"30b5d498-2e0c-49b2-a81c-cbb1c3bf1ebd"},"children":[{"data":{"text":"生成器网络设计","note":"从随机噪声生成逼真数据的神经网络，通常使用转置卷积或上采样层逐步增加分辨率。","nextSystemPrompt":"","color":"#3498DB","expand":true,"richText":false,"isActive":false,"uid":"e67fb551-7ba9-4cc5-b1d6-fd39f15ab4ef"},"children":[]},{"data":{"text":"判别器网络架构","note":"区分真实数据和生成数据的分类器，通常使用卷积神经网络提取特征并进行二分类。","nextSystemPrompt":"","color":"#E74C3C","expand":true,"richText":false,"isActive":false,"uid":"1670b814-0b28-4874-a598-fbb6f365671d"},"children":[]},{"data":{"text":"对抗训练过程","note":"生成器和判别器交替训练，形成零和博弈，最终达到纳什均衡状态。","nextSystemPrompt":"","color":"#F39C12","expand":true,"richText":false,"isActive":false,"uid":"b9b23419-b755-4c64-bbba-4015a0e9b4af"},"children":[]},{"data":{"text":"损失函数设计","note":"包括原始GAN损失、WGAN损失、LSGAN损失等不同的对抗损失函数设计。","nextSystemPrompt":"","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"a32b24d7-b791-4198-80ee-7454fb03e96b"},"children":[]},{"data":{"text":"训练稳定性问题","note":"GAN训练容易出现模式崩塌、梯度消失等问题，需要特殊的训练技巧和正则化方法。","nextSystemPrompt":"","color":"#9B59B6","expand":true,"richText":false,"isActive":false,"uid":"d1c26c5a-5d82-4c6f-9127-9a8adc9791c3"},"children":[]},{"data":{"text":"DCGAN深度卷积","note":"使用深度卷积网络的GAN变种，提出了稳定训练的架构设计原则。","nextSystemPrompt":"","color":"#1ABC9C","expand":true,"richText":false,"isActive":false,"uid":"4b55ddd0-61f6-41ca-ad49-1747b277e303"},"children":[]},{"data":{"text":"条件GAN扩展","note":"在生成过程中加入条件信息，实现可控的数据生成，如类别标签或文本描述。","nextSystemPrompt":"","color":"#34495E","expand":true,"richText":false,"isActive":false,"uid":"f5f8f5dd-8542-458f-b045-b467b86df9f1"},"children":[]},{"data":{"text":"CycleGAN循环一致","note":"通过循环一致性损失实现无配对数据的域转换，广泛应用于风格迁移任务。","nextSystemPrompt":"","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"389ce710-86bd-482b-9674-499e4cae6a23"},"children":[]},{"data":{"text":"StyleGAN风格控制","note":"通过风格向量控制生成图像的不同层次特征，实现高质量和可控的人脸生成。","nextSystemPrompt":"","color":"#8E44AD","expand":true,"richText":false,"isActive":false,"uid":"e024f581-1eb8-447c-a099-95d4fdbb4ec7"},"children":[]},{"data":{"text":"GAN评估指标","note":"包括IS、FID、LPIPS等评估生成质量和多样性的指标，以及人工评估方法。","nextSystemPrompt":"","color":"#D35400","expand":true,"richText":false,"isActive":false,"uid":"e0055cc3-e10c-4caf-a27a-03befd77d5cd"},"children":[]}]},{"data":{"text":"深度学习优化算法","note":"优化算法是深度学习训练的核心，负责更新模型参数以最小化损失函数。从基础的梯度下降到自适应学习率的Adam，不同优化器有不同的收敛特性和适用场景。学习率调度、动量、自适应梯度等技术进一步提升了训练效率和模型性能。理解优化算法的原理对于成功训练深度模型至关重要。","nextSystemPrompt":"基于深度学习优化算法，总结出梯度下降、动量方法、自适应优化器、学习率调度等子知识点","color":"#1ABC9C","expand":true,"richText":false,"isActive":false,"uid":"f79ea8cf-4a82-4ca0-b867-a20d09481129"},"children":[{"data":{"text":"随机梯度下降SGD","note":"最基础的优化算法，使用单个样本或小批量样本的梯度更新参数，简单高效但收敛可能不稳定。","nextSystemPrompt":"","color":"#3498DB","expand":true,"richText":false,"isActive":false,"uid":"ad9506fa-8388-489d-8d2c-73ab80f14771"},"children":[]},{"data":{"text":"动量优化方法","note":"通过累积历史梯度信息加速收敛，减少震荡，包括标准动量和Nesterov动量。","nextSystemPrompt":"","color":"#E74C3C","expand":true,"richText":false,"isActive":false,"uid":"db159d75-dcff-4684-89d7-21fbf638b49e"},"children":[]},{"data":{"text":"AdaGrad自适应梯度","note":"根据历史梯度自动调整每个参数的学习率，适合处理稀疏数据，但学习率会单调递减。","nextSystemPrompt":"","color":"#F39C12","expand":true,"richText":false,"isActive":false,"uid":"a9aada92-5658-4e54-95f5-bf38683cded1"},"children":[]},{"data":{"text":"RMSprop改进算法","note":"改进AdaGrad的学习率衰减问题，使用指数移动平均计算梯度平方的累积。","nextSystemPrompt":"","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"5261bde7-5c84-4d38-a5e4-7f7efdc0d937"},"children":[]},{"data":{"text":"Adam优化器","note":"结合动量和自适应学习率的优势，是目前最流行的优化器，在大多数任务上表现良好。","nextSystemPrompt":"","color":"#9B59B6","expand":true,"richText":false,"isActive":false,"uid":"92ba1e00-5381-41c1-87db-c1049b240ead"},"children":[]},{"data":{"text":"学习率调度策略","note":"包括固定衰减、余弦退火、warm-up等学习率调整策略，影响模型的收敛速度和最终性能。","nextSystemPrompt":"","color":"#E67E22","expand":true,"richText":false,"isActive":false,"uid":"1462bb1d-91d5-4bbb-8ab3-b2a7d892ba83"},"children":[]},{"data":{"text":"梯度裁剪技术","note":"通过限制梯度的范数防止梯度爆炸，特别在RNN训练中广泛使用。","nextSystemPrompt":"","color":"#34495E","expand":true,"richText":false,"isActive":false,"uid":"c4289f29-c715-417d-985a-731c5e271a99"},"children":[]},{"data":{"text":"二阶优化方法","note":"利用Hessian矩阵信息的优化方法，如L-BFGS，收敛更快但计算复杂度高。","nextSystemPrompt":"","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"ebd03ea6-ebd6-47cc-a2ac-3a63ca28de52"},"children":[]},{"data":{"text":"优化器超参数调优","note":"学习率、beta参数、权重衰减等超参数的选择和调优策略，对训练效果有重要影响。","nextSystemPrompt":"","color":"#8E44AD","expand":true,"richText":false,"isActive":false,"uid":"74dd8608-bbc3-4f64-8129-6aab614c60e2"},"children":[]},{"data":{"text":"分布式优化算法","note":"在多GPU或多机环境下的参数同步和梯度聚合方法，包括数据并行和模型并行。","nextSystemPrompt":"","color":"#D35400","expand":true,"richText":false,"isActive":false,"uid":"a7f05122-deb5-492e-baea-ea85821bd95f"},"children":[]}]},{"data":{"text":"正则化与防过拟合技术","note":"正则化技术是防止深度模型过拟合的重要手段，通过在训练过程中引入约束或噪声来提高模型的泛化能力。包括权重衰减、Dropout、批量归一化、数据增强等多种方法。这些技术从不同角度解决过拟合问题，使模型在训练数据上学到的知识能够更好地迁移到测试数据上。","nextSystemPrompt":"基于正则化与防过拟合技术，总结出Dropout、权重衰减、数据增强、早停法等关键子知识点","color":"#34495E","expand":true,"richText":false,"isActive":false,"uid":"b280f3c6-8ab7-4900-9eb5-23b64823b935"},"children":[{"data":{"text":"Dropout随机失活","note":"训练时随机将部分神经元输出置零，减少神经元间的共适应，是最常用的正则化技术之一。","nextSystemPrompt":"","color":"#3498DB","expand":true,"richText":false,"isActive":false,"uid":"af656f1e-0f23-436d-ad4c-855d3db96d6e"},"children":[]},{"data":{"text":"权重衰减L2正则","note":"在损失函数中添加权重的L2范数惩罚项，防止权重过大，促进模型学习更简单的表示。","nextSystemPrompt":"","color":"#E74C3C","expand":true,"richText":false,"isActive":false,"uid":"906eeafe-52ee-4b92-b9c2-1afc279dcf97"},"children":[]},{"data":{"text":"数据增强技术","note":"通过旋转、缩放、裁剪等变换增加训练数据的多样性，提高模型的泛化能力。","nextSystemPrompt":"","color":"#F39C12","expand":true,"richText":false,"isActive":false,"uid":"143cb79f-ea5d-475c-bc9f-80692fbcfcfd"},"children":[]},{"data":{"text":"早停法策略","note":"监控验证集性能，当验证误差开始上升时停止训练，防止模型在训练集上过度拟合。","nextSystemPrompt":"","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"584834d3-106b-499a-ba7a-762c013ff9e9"},"children":[]},{"data":{"text":"批量归一化BN","note":"归一化每层的输入分布，加速训练收敛，同时具有一定的正则化效果。","nextSystemPrompt":"","color":"#9B59B6","expand":true,"richText":false,"isActive":false,"uid":"106e8f97-18c4-4e3a-aac4-3f1798acc815"},"children":[]},{"data":{"text":"标签平滑技术","note":"将硬标签转换为软标签，减少模型对训练数据的过度自信，提高泛化性能。","nextSystemPrompt":"","color":"#1ABC9C","expand":true,"richText":false,"isActive":false,"uid":"2c133776-5011-42c5-b882-6107875fc8ce"},"children":[]},{"data":{"text":"DropConnect连接失活","note":"随机将权重连接置零而不是神经元输出，是Dropout的一种变种形式。","nextSystemPrompt":"","color":"#E67E22","expand":true,"richText":false,"isActive":false,"uid":"73370c4c-e5b7-4e3a-a14d-0c622425dba8"},"children":[]},{"data":{"text":"噪声注入方法","note":"在输入、权重或梯度中添加噪声，增强模型的鲁棒性和泛化能力。","nextSystemPrompt":"","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"83c807d7-9230-496e-922f-48f2d5731d40"},"children":[]},{"data":{"text":"集成学习方法","note":"训练多个模型并组合其预测结果，通过模型多样性减少过拟合风险。","nextSystemPrompt":"","color":"#8E44AD","expand":true,"richText":false,"isActive":false,"uid":"28739902-bbda-4d17-8b00-bfaa84aaaf78"},"children":[]},{"data":{"text":"交叉验证技术","note":"通过多折交叉验证评估模型性能，更可靠地检测过拟合现象。","nextSystemPrompt":"","color":"#D35400","expand":true,"richText":false,"isActive":false,"uid":"9b9deed8-2ef7-463c-8d75-557dd4ecb93f"},"children":[]}]},{"data":{"text":"迁移学习与预训练模型","note":"迁移学习利用在大规模数据集上预训练的模型知识，通过微调适应特定任务，大大减少了训练时间和数据需求。预训练模型如ImageNet上的CNN模型、大规模语言模型等，为下游任务提供了强大的特征表示基础。迁移学习已成为深度学习应用的标准范式，特别是在数据稀缺的领域。","nextSystemPrompt":"基于迁移学习与预训练模型，总结出特征提取、微调策略、领域适应、多任务学习等子知识点","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"0f97d5aa-1d81-47a4-b84d-ac6c1d8fabbd"},"children":[{"data":{"text":"特征提取方法","note":"使用预训练模型的前几层作为特征提取器，冻结参数，只训练新添加的分类器层。","nextSystemPrompt":"","color":"#3498DB","expand":true,"richText":false,"isActive":false,"uid":"18c49a11-8808-4cda-9fdc-571bb9724fb9"},"children":[]},{"data":{"text":"端到端微调","note":"在预训练模型基础上，使用较小的学习率对整个网络进行微调，适应新任务。","nextSystemPrompt":"","color":"#E74C3C","expand":true,"richText":false,"isActive":false,"uid":"5601326c-ff47-4dc5-9e68-58f5da85651c"},"children":[]},{"data":{"text":"层级微调策略","note":"逐层解冻并微调网络参数，从顶层开始，逐步向底层扩展，平衡稳定性和适应性。","nextSystemPrompt":"","color":"#F39C12","expand":true,"richText":false,"isActive":false,"uid":"46ed5555-373d-4335-8035-76566a7c2ec0"},"children":[]},{"data":{"text":"领域适应技术","note":"处理源域和目标域数据分布差异的方法，包括对抗训练、域判别器等技术。","nextSystemPrompt":"","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"91e52d72-ecc2-4554-a0ce-0bfb9dbbfeb6"},"children":[]},{"data":{"text":"多任务学习框架","note":"同时学习多个相关任务，通过共享表示提高各任务的性能和泛化能力。","nextSystemPrompt":"","color":"#9B59B6","expand":true,"richText":false,"isActive":false,"uid":"46b87b7b-b920-49d2-8285-13b694c0ed1f"},"children":[]},{"data":{"text":"预训练策略设计","note":"自监督学习、对比学习等预训练方法，在无标签数据上学习通用特征表示。","nextSystemPrompt":"","color":"#1ABC9C","expand":true,"richText":false,"isActive":false,"uid":"4cef6203-52bb-4dbc-ab60-1453fd5e0557"},"children":[]},{"data":{"text":"知识蒸馏技术","note":"将大模型的知识转移到小模型中，实现模型压缩的同时保持性能。","nextSystemPrompt":"","color":"#E67E22","expand":true,"richText":false,"isActive":false,"uid":"e6e7f72b-3850-4bf2-a401-db0efc9685a7"},"children":[]},{"data":{"text":"少样本学习","note":"在极少标注数据下快速适应新任务的方法，包括元学习、原型网络等。","nextSystemPrompt":"","color":"#34495E","expand":true,"richText":false,"isActive":false,"uid":"8e7ba913-df41-474b-aa8e-de0d0e0bdab5"},"children":[]},{"data":{"text":"跨模态迁移","note":"在不同模态（如图像到文本）之间进行知识迁移的方法和技术。","nextSystemPrompt":"","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"1175e1db-0ea1-444c-9482-91c3c15b0a31"},"children":[]},{"data":{"text":"迁移学习评估","note":"评估迁移效果的指标和方法，包括迁移性能、负迁移检测等。","nextSystemPrompt":"","color":"#8E44AD","expand":true,"richText":false,"isActive":false,"uid":"938ad8c4-efae-425f-b09a-4ba996bc45ce"},"children":[]}]},{"data":{"text":"深度学习应用领域","note":"深度学习在计算机视觉、自然语言处理、语音识别、推荐系统等众多领域取得了突破性进展。每个应用领域都有其特定的模型架构、数据处理方法和评估指标。从图像分类、目标检测到机器翻译、对话系统，深度学习正在改变各个行业的技术格局，推动人工智能的产业化应用。","nextSystemPrompt":"基于深度学习应用领域，总结出计算机视觉、自然语言处理、语音识别、推荐系统等应用子领域","color":"#8E44AD","expand":true,"richText":false,"isActive":false,"uid":"08d10f57-e7ae-4e5e-ace4-8a9e1bb90af2"},"children":[{"data":{"text":"图像分类与识别","note":"使用CNN对图像进行分类，从简单的数字识别到复杂的场景理解，是计算机视觉的基础任务。","nextSystemPrompt":"","color":"#3498DB","expand":true,"richText":false,"isActive":false,"uid":"f2de9c5d-67cd-46a0-bdfa-106166a14ca6"},"children":[]},{"data":{"text":"目标检测定位","note":"在图像中定位和识别多个目标对象，包括R-CNN、YOLO、SSD等不同的检测框架。","nextSystemPrompt":"","color":"#E74C3C","expand":true,"richText":false,"isActive":false,"uid":"4eacc8a4-ddde-4b0e-872a-7ba08dae403e"},"children":[]},{"data":{"text":"语义分割任务","note":"对图像中每个像素进行分类，实现精确的区域分割，广泛应用于医学影像和自动驾驶。","nextSystemPrompt":"","color":"#F39C12","expand":true,"richText":false,"isActive":false,"uid":"0e23ff84-149e-4f51-9be4-726c8727cdcc"},"children":[]},{"data":{"text":"机器翻译系统","note":"使用序列到序列模型和注意力机制实现不同语言间的自动翻译。","nextSystemPrompt":"","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"e829261c-fc14-4975-8f4e-73936bb45104"},"children":[]},{"data":{"text":"情感分析应用","note":"分析文本的情感倾向，广泛应用于社交媒体监控、产品评价分析等场景。","nextSystemPrompt":"","color":"#9B59B6","expand":true,"richText":false,"isActive":false,"uid":"e5e9738f-7825-4a43-ab8b-d8193a9a449b"},"children":[]},{"data":{"text":"语音识别技术","note":"将语音信号转换为文本，结合RNN、CNN和注意力机制实现高精度识别。","nextSystemPrompt":"","color":"#1ABC9C","expand":true,"richText":false,"isActive":false,"uid":"dad6082d-6a0a-4778-8754-c327ce1f8e67"},"children":[]},{"data":{"text":"推荐系统算法","note":"基于用户行为和物品特征进行个性化推荐，广泛应用于电商和内容平台。","nextSystemPrompt":"","color":"#E67E22","expand":true,"richText":false,"isActive":false,"uid":"75a240d9-9dd9-471d-bbbf-48127d70bc0e"},"children":[]},{"data":{"text":"强化学习应用","note":"通过与环境交互学习最优策略，在游戏、机器人控制、自动驾驶等领域有重要应用。","nextSystemPrompt":"","color":"#34495E","expand":true,"richText":false,"isActive":false,"uid":"a00d60b6-51fb-4e3a-a1f1-26b6d816e59d"},"children":[]},{"data":{"text":"医疗影像诊断","note":"利用深度学习分析医学图像，辅助疾病诊断，在放射学、病理学等领域显示巨大潜力。","nextSystemPrompt":"","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"ad25648d-bed1-45f5-95b8-e1fdbde813f7"},"children":[]},{"data":{"text":"自动驾驶技术","note":"综合运用计算机视觉、传感器融合、路径规划等技术实现车辆的自主导航。","nextSystemPrompt":"","color":"#D35400","expand":true,"richText":false,"isActive":false,"uid":"efdcee54-da23-487f-960c-db4a060e62c4"},"children":[]}]},{"data":{"text":"模型部署与工程化","note":"将训练好的深度学习模型部署到生产环境需要考虑推理效率、资源消耗、可扩展性等工程问题。包括模型压缩、量化、蒸馏等技术来减小模型大小和计算复杂度。同时需要构建完整的MLOps流程，包括模型版本管理、监控、A/B测试等，确保模型在生产环境中稳定可靠地运行。","nextSystemPrompt":"基于模型部署与工程化，总结出模型压缩、推理优化、服务化部署、监控运维等工程子知识点","color":"#D35400","expand":true,"richText":false,"isActive":false,"uid":"2cec993f-d7b9-4e2c-832e-8a318d28c8b5"},"children":[{"data":{"text":"模型压缩技术","note":"通过剪枝、量化、知识蒸馏等方法减小模型大小，降低存储和计算需求。","nextSystemPrompt":"","color":"#3498DB","expand":true,"richText":false,"isActive":false,"uid":"e9a6aa90-dd1e-4be7-a774-9e5ad65d64f3"},"children":[]},{"data":{"text":"推理加速优化","note":"使用TensorRT、ONNX等工具优化模型推理速度，支持GPU、TPU等硬件加速。","nextSystemPrompt":"","color":"#E74C3C","expand":true,"richText":false,"isActive":false,"uid":"5f8f2940-fb81-422e-8660-c5788995cd21"},"children":[]},{"data":{"text":"边缘计算部署","note":"在移动设备、嵌入式系统等资源受限环境下部署深度学习模型。","nextSystemPrompt":"","color":"#F39C12","expand":true,"richText":false,"isActive":false,"uid":"743d2c95-c11f-487d-b762-0ab832e6775f"},"children":[]},{"data":{"text":"模型服务化架构","note":"将模型封装为REST API或gRPC服务，支持高并发访问和负载均衡。","nextSystemPrompt":"","color":"#27AE60","expand":true,"richText":false,"isActive":false,"uid":"ad03cde0-7823-4053-aa40-3125923a284a"},"children":[]},{"data":{"text":"容器化部署方案","note":"使用Docker、Kubernetes等容器技术实现模型的标准化部署和弹性伸缩。","nextSystemPrompt":"","color":"#9B59B6","expand":true,"richText":false,"isActive":false,"uid":"c525d4e5-eba3-4012-9403-f115f7d4a39f"},"children":[]},{"data":{"text":"模型版本管理","note":"建立完整的模型版本控制体系，支持模型回滚、灰度发布等功能。","nextSystemPrompt":"","color":"#1ABC9C","expand":true,"richText":false,"isActive":false,"uid":"0c6c0482-1ee6-407a-83b9-196a08ccae29"},"children":[]},{"data":{"text":"性能监控体系","note":"监控模型的推理延迟、准确率、资源使用等指标，及时发现性能问题。","nextSystemPrompt":"","color":"#E67E22","expand":true,"richText":false,"isActive":false,"uid":"c88cc9cc-bc01-430e-a399-7e9878b08bc5"},"children":[]},{"data":{"text":"A/B测试框架","note":"通过对照实验评估新模型的效果，支持数据驱动的模型迭代决策。","nextSystemPrompt":"","color":"#34495E","expand":true,"richText":false,"isActive":false,"uid":"bac61114-1cb5-4981-a384-34a2e985375a"},"children":[]},{"data":{"text":"数据流水线设计","note":"构建从数据收集、预处理到模型训练的自动化流水线，提高开发效率。","nextSystemPrompt":"","color":"#16A085","expand":true,"richText":false,"isActive":false,"uid":"732a3b97-644a-40d0-925d-1b6c5a78d79b"},"children":[]},{"data":{"text":"安全性与隐私保护","note":"在模型部署中考虑对抗攻击防护、数据隐私保护、模型安全等安全问题。","nextSystemPrompt":"","color":"#8E44AD","expand":true,"richText":false,"isActive":false,"uid":"b4569892-c3b3-4ecf-af66-7741bd523238"},"children":[]}]}],"smmVersion":"0.14.0-fix.1"}